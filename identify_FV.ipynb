{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfaf84b9-483a-4b13-b08c-a8fa0b383470",
   "metadata": {},
   "source": [
    "# Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "198a5357-1519-4497-9d78-60f3990670a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "transaction=pd.read_excel(\"TRANSACTION_DETAIL.xlsx\") ##new transaction records without dummies\n",
    "past_transaction=pd.read_excel(\"FV_dummy_unit_updated.xlsx\") #old transaction records with dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1104d92f-d374-42e7-8789-3c0f063b972f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FV_dummy\n",
       "0     33414\n",
       "1      6883\n",
       "6      1524\n",
       "5       359\n",
       "10      217\n",
       "3       207\n",
       "9       193\n",
       "12      165\n",
       "2       110\n",
       "13       77\n",
       "11       37\n",
       "7        28\n",
       "8        25\n",
       "4         3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past_transaction['FV_dummy'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8905c975-42cd-4ec8-b2b2-33e27c5823ff",
   "metadata": {},
   "source": [
    "get unique product description from FV_dummy 1 to 13 (FV_dummy 1 from fvs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32ec08f0-9302-423d-ab6d-aa160cc8a3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with pd.ExcelWriter(\"unique_products_all.xlsx\", engine=\"xlsxwriter\") as writer:\n",
    "    for i in range(0, 14):  # FV_dummy values 2 through 13\n",
    "        # Filter rows where FV_dummy == i\n",
    "        filtered_df = past_transaction[past_transaction['FV_dummy'] == i]\n",
    "\n",
    "        # Select the relevant columns and drop duplicates\n",
    "        unique_products_i = filtered_df[['PRODUCT_DESCRIPTION', 'DEPARTMENT_NAME',\n",
    "                                         'CATEGORY_NAME', 'SECTION_NAME', 'SIZE',\n",
    "                                         'FV_dummy']].drop_duplicates()\n",
    "\n",
    "        # Save each result to a separate sheet\n",
    "        unique_products_i.to_excel(writer, sheet_name=f\"unique_products_{i}\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f3c1c2a-f91e-4bdc-b9b9-4d3590d238e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet: unique_products_0, Shape: (10248, 6)\n",
      "Sheet: unique_products_1, Shape: (938, 6)\n",
      "Sheet: unique_products_2, Shape: (42, 6)\n",
      "Sheet: unique_products_3, Shape: (83, 6)\n",
      "Sheet: unique_products_4, Shape: (3, 6)\n",
      "Sheet: unique_products_5, Shape: (89, 6)\n",
      "Sheet: unique_products_6, Shape: (431, 6)\n",
      "Sheet: unique_products_7, Shape: (7, 6)\n",
      "Sheet: unique_products_8, Shape: (17, 6)\n",
      "Sheet: unique_products_9, Shape: (87, 6)\n",
      "Sheet: unique_products_10, Shape: (47, 6)\n",
      "Sheet: unique_products_11, Shape: (22, 6)\n",
      "Sheet: unique_products_12, Shape: (63, 6)\n",
      "Sheet: unique_products_13, Shape: (38, 6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load all sheets into a dictionary of DataFrames\n",
    "sheets_dict = pd.read_excel(\"unique_products_all.xlsx\", sheet_name=None)\n",
    "\n",
    "\n",
    "# If you want to loop through them:\n",
    "for sheet_name, df in sheets_dict.items():\n",
    "    print(f\"Sheet: {sheet_name}, Shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90c8a3f3-e96f-4787-8154-18ce77508395",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PID', 'FULL_DATE', 'TRANSACTION_HEADER_KEY', 'STORE_NUMBER', 'AREA',\n",
       "       'DEPARTMENT_NAME', 'CATEGORY_NAME', 'SECTION_NAME', 'SUB_SECTION_NAME',\n",
       "       'PRIMARY_UPC', 'PRODUCT_DESCRIPTION', 'SIZE', 'UNIT_OF_MEASURE',\n",
       "       'SALES', 'UNITS_WEIGHT', 'UNITS_PACKAGES', 'AD_TYPE_DESCRIPTION',\n",
       "       'AVG_PRICE_PER_MEASURE', 'AVG_PRICE_PER_PACK', 'HUMAN_CONSUMABLE_CODE',\n",
       "       'DIETITIAN_PICK', 'WIC_FLAG', 'FOOD_STAMP_FLAG'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transaction.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c7f260-9bdd-4b33-898d-d71417158c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with FV_dummy as missing\n",
    "transaction['FV_dummy_1'] = 0 \n",
    "\n",
    "# Loop through unique_products_2 ... unique_products_13\n",
    "for i in range(1, 14):\n",
    "    sheet_name = str(i)   # sheet names are strings: \"1\", \"2\", ..., \"13\"\n",
    "    \n",
    "    if sheet_name in sheets_dict:   # check if the sheet exists\n",
    "        product_list = sheets_dict[sheet_name].iloc[:, 0].dropna().values  # first column\n",
    "        \n",
    "        # Assign FV_dummy = i if the product matches\n",
    "        transaction.loc[\n",
    "            transaction['PRODUCT_DESCRIPTION'].isin(product_list),\n",
    "            'FV_dummy_1'\n",
    "        ] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1db87319-022e-45d7-a260-39942d96f701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FV_dummy column: 1 if PRODUCT_DESCRIPTION in fv_list, else 0\n",
    "import pandas as pd\n",
    "\n",
    "# Start with FV_dummy as missing\n",
    "transaction['FV_dummy'] = 0 \n",
    "\n",
    "# Loop through unique_products_2 ... unique_products_13\n",
    "for i in range(1, 14):\n",
    "    product_list = unique_products[i]['PRODUCT_DESCRIPTION'].values\n",
    "    \n",
    "    # Assign FV_dummy = i if the product matches\n",
    "    transaction.loc[transaction['PRODUCT_DESCRIPTION'].isin(product_list), 'FV_dummy'] = i\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5198e3ac-5775-4db9-a0a8-3869dc41d957",
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction.to_excel(\"TRANSACTION_DETAIL_8_8_dummy.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e88b48-df77-4399-a5f5-525ed5212228",
   "metadata": {},
   "source": [
    "find undefined products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcfcc63c-02e6-4e46-8ebe-be2a423430e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = transaction[transaction['FV_dummy'] == 0]\n",
    "\n",
    "    # Select the relevant columns and drop duplicates\n",
    "unique_products0_new = filtered_df[['PRODUCT_DESCRIPTION', 'DEPARTMENT_NAME', \n",
    "                                     'CATEGORY_NAME', 'SECTION_NAME', \n",
    "                                     'FV_dummy']].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fcaf776-66a8-4d8b-b2d8-6c8289c018e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_products0 = pd.read_excel(\"unique_products_0.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1936819-1921-471d-b94e-94677718673f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10248, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_products0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69d1b0a1-8a76-462e-b397-7e07127a1ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12095, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_products0_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9d4572d-5c73-4c65-a6a1-9b0b667d06c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_products0_new['defined'] = 0\n",
    "product_list = unique_products0['PRODUCT_DESCRIPTION'].values\n",
    "unique_products0_new.loc[unique_products0_new['PRODUCT_DESCRIPTION'].isin(product_list), 'defined'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2faed8e3-b6ba-44a7-a71e-111a7cf5eafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined\n",
       "1    9653\n",
       "0    2442\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_products0_new['defined'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b3b2f49-0faf-4da8-a77c-f8c756c6a43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "undefined = unique_products0_new[unique_products0_new['defined'] == 0]\n",
    "undefined.to_excel(\"undefined.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c900348b-fbdc-471a-a6ae-d3c3a228472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_products0_new.to_excel(\"dummy0_case.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b76fe4e-8629-4502-80e9-7dc6232a3a7e",
   "metadata": {},
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3bb6f0a-bcc9-4ce0-8362-dcf2286c0630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12095, 5)\n",
      "(870, 5)\n",
      "(42, 5)\n",
      "(84, 5)\n",
      "(3, 5)\n",
      "(86, 5)\n",
      "(499, 5)\n",
      "(7, 5)\n",
      "(16, 5)\n",
      "(84, 5)\n",
      "(47, 5)\n",
      "(22, 5)\n",
      "(63, 5)\n",
      "(37, 5)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 14):  # FV_dummy values 2 through 13\n",
    "    # Filter rows where FV_dummy == i\n",
    "    filtered_df = transaction[transaction['FV_dummy'] == i]\n",
    "\n",
    "    # Select the relevant columns and drop duplicates\n",
    "    unique_products_i = filtered_df[['PRODUCT_DESCRIPTION', 'DEPARTMENT_NAME', \n",
    "                                     'CATEGORY_NAME', 'SECTION_NAME', \n",
    "                                     'FV_dummy']].drop_duplicates()\n",
    "    filename = f\"unique_products_{i}\"\n",
    "    print(unique_products_i.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52bc7a0-02e6-4c96-8709-0f5063266e02",
   "metadata": {},
   "source": [
    "check difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e8bf0f-c135-4474-9c86-97ef72f4407d",
   "metadata": {},
   "source": [
    "3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b37673da-ffd6-450e-bef6-453ca89729cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_products3 = pd.read_excel(\"unique_products_3.xlsx\")\n",
    "unique_products3=unique_products3.drop(columns='FV_dummy_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "804161a6-3e47-4067-b38e-dc6a0524aaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = transaction[transaction['FV_dummy'] == 3]\n",
    "\n",
    "    # Select the relevant columns and drop duplicates\n",
    "unique_products3_new = filtered_df[['PRODUCT_DESCRIPTION', 'DEPARTMENT_NAME', \n",
    "                                     'CATEGORY_NAME', 'SECTION_NAME', 'SIZE',\n",
    "                                     'FV_dummy']].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95f5739e-03ae-4ced-a2bd-7ca3828b968f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_DESCRIPTION</th>\n",
       "      <th>DEPARTMENT_NAME</th>\n",
       "      <th>CATEGORY_NAME</th>\n",
       "      <th>SECTION_NAME</th>\n",
       "      <th>SIZE</th>\n",
       "      <th>FV_dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mt Olive - Kosher Dills (46 Oz)</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>GLASS</td>\n",
       "      <td>PICKLES / PEPPERS</td>\n",
       "      <td>46.00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Schnucks - Kosher Sandwich Slices Pickles (16 Oz)</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>GLASS</td>\n",
       "      <td>PICKLES / PEPPERS</td>\n",
       "      <td>16.00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mt Olive - Mild Okra (16 Oz)</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>GLASS</td>\n",
       "      <td>PICKLES / PEPPERS</td>\n",
       "      <td>16.00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mt Olive - Dill Pickles (46 Oz)</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>GLASS</td>\n",
       "      <td>PICKLES / PEPPERS</td>\n",
       "      <td>46.00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Schnucks - Ripe Sliced Olives (2.25 Oz)</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>GLASS</td>\n",
       "      <td>OLIVES / CAPERS</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 PRODUCT_DESCRIPTION DEPARTMENT_NAME  \\\n",
       "0                    Mt Olive - Kosher Dills (46 Oz)         GROCERY   \n",
       "1  Schnucks - Kosher Sandwich Slices Pickles (16 Oz)         GROCERY   \n",
       "2                       Mt Olive - Mild Okra (16 Oz)         GROCERY   \n",
       "3                    Mt Olive - Dill Pickles (46 Oz)         GROCERY   \n",
       "4            Schnucks - Ripe Sliced Olives (2.25 Oz)         GROCERY   \n",
       "\n",
       "  CATEGORY_NAME       SECTION_NAME   SIZE  FV_dummy  \n",
       "0         GLASS  PICKLES / PEPPERS  46.00         3  \n",
       "1         GLASS  PICKLES / PEPPERS  16.00         3  \n",
       "2         GLASS  PICKLES / PEPPERS  16.00         3  \n",
       "3         GLASS  PICKLES / PEPPERS  46.00         3  \n",
       "4         GLASS    OLIVES / CAPERS   2.25         3  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_products3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfc8f0c9-f167-417e-8024-089e388c78c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a source column to each DataFrame\n",
    "unique_products3['source'] = 'old'\n",
    "unique_products3_new['source'] = 'new'\n",
    "\n",
    "# Concatenate and keep only different rows\n",
    "diff_rows = pd.concat([unique_products3, unique_products3_new]).drop_duplicates(subset=unique_products3.columns[:-1], keep=False)\n",
    "\n",
    "diff_rows\n",
    "diff_rows.to_excel(\"unique_products3_diff.xlsx\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4810abb-5f1e-4d1c-8bbf-569e007b1066",
   "metadata": {},
   "source": [
    "6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66bf0c61-e99f-43d7-b7fd-d9ad638b1cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_products6 = pd.read_excel(\"unique_products_6.xlsx\")\n",
    "unique_products6=unique_products6.drop(columns='FV_dummy_2')\n",
    "filtered_df = transaction[transaction['FV_dummy'] == 6]\n",
    "\n",
    "    # Select the relevant columns and drop duplicates\n",
    "unique_products6_new = filtered_df[['PRODUCT_DESCRIPTION', 'DEPARTMENT_NAME', \n",
    "                                     'CATEGORY_NAME', 'SECTION_NAME', 'SIZE',\n",
    "                                     'FV_dummy']].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cdf4a512-4e5a-490f-93b4-fe746d1cc62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a source column to each DataFrame\n",
    "unique_products6['source'] = 'old'\n",
    "unique_products6_new['source'] = 'new'\n",
    "\n",
    "# Concatenate and keep only different rows\n",
    "diff_rows = pd.concat([unique_products6, unique_products6_new]).drop_duplicates(subset=unique_products6.columns[:-1], keep=False)\n",
    "\n",
    "diff_rows=diff_rows.drop_duplicates()\n",
    "diff_rows.to_excel(\"unique_products6_diff.xlsx\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7077ad53-0163-44d3-b810-0aff368117ec",
   "metadata": {},
   "source": [
    "# Step 3: Generate a list of new products of dummies mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad393a71-0b4e-4be1-ad31-9da529e5f6b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m transaction\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTRANSACTION_DETAIL.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# import new new transaction records without dummies\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "transaction=pd.read_excel(\"TRANSACTION_DETAIL.xlsx\") # import new new transaction records without dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9270de43-fc31-4a57-a265-64dc1be07473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet: 2_9, Shape: (33, 1)\n",
      "Sheet: 2_8, Shape: (21, 1)\n",
      "Sheet: 2_7, Shape: (67, 1)\n",
      "Sheet: 2_6, Shape: (241, 1)\n",
      "Sheet: 2_5, Shape: (26, 1)\n",
      "Sheet: 2_4, Shape: (5, 1)\n",
      "Sheet: 2_3, Shape: (142, 1)\n",
      "Sheet: 2_2, Shape: (133, 1)\n",
      "Sheet: 2_1, Shape: (418, 1)\n",
      "Sheet: 13, Shape: (43, 1)\n",
      "Sheet: 12, Shape: (71, 1)\n",
      "Sheet: 11, Shape: (33, 1)\n",
      "Sheet: 10, Shape: (47, 1)\n",
      "Sheet: 9, Shape: (96, 1)\n",
      "Sheet: 8, Shape: (19, 1)\n",
      "Sheet: 7, Shape: (7, 1)\n",
      "Sheet: 6, Shape: (533, 1)\n",
      "Sheet: 5, Shape: (102, 1)\n",
      "Sheet: 4, Shape: (3, 1)\n",
      "Sheet: 3, Shape: (94, 1)\n",
      "Sheet: 2, Shape: (51, 1)\n",
      "Sheet: 1, Shape: (1088, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load all sheets into a dictionary of DataFrames\n",
    "sheets_dict = pd.read_excel(\"products of dummies.xlsx\", sheet_name=None) # import file of product lists of dummies\n",
    "\n",
    "\n",
    "# If you want to loop through them:\n",
    "for sheet_name, df in sheets_dict.items():\n",
    "    print(f\"Sheet: {sheet_name}, Shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e48a80e9-a8a9-4b56-9600-13dbede28e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with FV_dummy_1 as 0\n",
    "transaction['FV_dummy_1'] = 0 \n",
    "\n",
    "# Loop through unique_products_2 ... unique_products_13\n",
    "for i in range(1, 14):\n",
    "    sheet_name = str(i)   # sheet names are strings: \"1\", \"2\", ..., \"13\"\n",
    "    \n",
    "    if sheet_name in sheets_dict:   # check if the sheet exists\n",
    "        product_list = sheets_dict[sheet_name].iloc[:, 0].dropna().values  # first column\n",
    "        \n",
    "        # Assign FV_dummy = i if the product matches\n",
    "        transaction.loc[\n",
    "            transaction['PRODUCT_DESCRIPTION'].isin(product_list),\n",
    "            'FV_dummy_1'\n",
    "        ] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5ef306b-8bc2-4cbd-a430-0f16da46d0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with FV_dummy_2 as 0\n",
    "transaction['FV_dummy_2'] = 0\n",
    "\n",
    "# Loop through sub-sheets \"2_1\" ... \"2_9\"\n",
    "for i in range(1, 10):\n",
    "    sheet_name = f\"2_{i}\"   # sheet names are strings like \"2_1\", \"2_2\", ...\n",
    "    \n",
    "    if sheet_name in sheets_dict:   # check if the sheet exists\n",
    "        product_list = sheets_dict[sheet_name].iloc[:, 0].dropna().values  # first column\n",
    "        \n",
    "        # Always assign FV_dummy_2 = 2 (not i)\n",
    "        transaction.loc[\n",
    "            transaction['PRODUCT_DESCRIPTION'].isin(product_list),\n",
    "            'FV_dummy_2'\n",
    "        ] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec013118-f233-4557-95e4-9608a6a36e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FV_dummy_1\n",
       "0     41792\n",
       "1      8676\n",
       "6      1965\n",
       "5       318\n",
       "10      269\n",
       "3       242\n",
       "12      221\n",
       "9       218\n",
       "2       134\n",
       "13      102\n",
       "11       59\n",
       "8        35\n",
       "7        28\n",
       "4         3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transaction['FV_dummy_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dfa05afc-3fd9-4bba-a642-79bca7a97954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FV_dummy_2\n",
       "0    45417\n",
       "1     4041\n",
       "6     3485\n",
       "3      462\n",
       "2      313\n",
       "7      149\n",
       "5       60\n",
       "8       58\n",
       "9       56\n",
       "4       21\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transaction['FV_dummy_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2cd04fd9-d1c5-44c2-9c53-07129edd5db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction.to_excel(\"transaction_mapped.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e932963-63b0-441b-abbb-148e0e15b143",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (IV)",
   "language": "python",
   "name": "iv_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
